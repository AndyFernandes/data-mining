{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Trabalho\n",
    "\n",
    "## Questão 1\n",
    "\n",
    "Implemente um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizaremos um conjunto de dados referente a qualidade de carros, disponível no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). Este dataset de carros possui as seguintes features e classe:\n",
    "\n",
    "** Attributos **\n",
    "1. buying: vhigh, high, med, low\n",
    "2. maint: vhigh, high, med, low\n",
    "3. doors: 2, 3, 4, 5, more\n",
    "4. persons: 2, 4, more\n",
    "5. lug_boot: small, med, big\n",
    "6. safety: low, med, high\n",
    "\n",
    "** Classes **\n",
    "1. unacc, acc, good, vgood\n",
    "\n",
    "## Questão 2\n",
    "Crie uma versão de sua implementação usando as funções disponíveis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) \n",
    "\n",
    "## Questão 3\n",
    "\n",
    "Analise a acurácia dos dois algoritmos e discuta a sua solução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Resolução\n",
    "\n",
    "## Questão 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [0.5, 0.6, 0.7, 1, 2, 3] => predizer a classe\n",
    "# \n",
    "# p(c|x) = P(X|C)*P(C) / P(X) => P(X|C)*P(C)\n",
    "# MAIOR P(C|X) ai a gente retorna que é a c\n",
    "\n",
    "# probabilidade da classe = p(c) => len(classe)/numero de linhas do dataset\n",
    "# probabilidade do elemento x dado a classe = p(x|c) = p(x[0]|c)*p(x[1]|c)*p(x[2]|c)*...*p(x[5]|c)  \n",
    "# X = [0.5, 0.6, 0.7, 1, 2, 3]\n",
    "# probabilidade do elemento x = p(x)\n",
    "\n",
    "# probabilidade de cada elemento para cada feature para cada classe => elemento/len(classe)\n",
    "# os valores da classe estão ordenados de 0 a 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from statistics import mean\n",
    "    \n",
    "def categorize_data(dataset, columns):\n",
    "    # Categorizando os dados\n",
    "    for feature in columns:\n",
    "        dataset[feature] = dataset[feature].astype('category')\n",
    "        dataset[feature] = dataset[feature].cat.codes\n",
    "    return dataset\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "    classes = [[], [], [], []]\n",
    "    # separando por classe\n",
    "    for row in dataset['class'].unique():\n",
    "        classes[row].append(dataset[dataset['class'] == row])\n",
    "    return classes\n",
    "\n",
    "def calculate_probabilities(dataset, features, classes): \n",
    "    #separando cada valor de cada feature pra cada classe\n",
    "    classes_unique = [[], [], [], []]\n",
    "    classes_feature_value = [[], [], [], []]\n",
    "    probs = [[], [], [], []]\n",
    "    for i in range(0, len(classes)):  \n",
    "        df = classes[i][0]\n",
    "        for ft in features:   \n",
    "            # Classes_unique vai ser usado para mapear os valores direito, já que não estão ordenados\n",
    "            classes_unique[i].append(df[ft].unique())\n",
    "            classes_feature_value[i].append(df[ft].unique())\n",
    "            probs[i].append(df[ft].unique())\n",
    "\n",
    "    # Gerando a contagem de cada elemento de cada feature para cada classe \n",
    "    # Percorre as classes\n",
    "    for i in range(0, len(classes)):  \n",
    "        df = classes[i][0]\n",
    "        # Percorre as features dentro da classe\n",
    "        for ft in range(0, len(features)):\n",
    "            # Percorrer os valores de dentro das features\n",
    "            for col in range(0, len(classes_unique[i][ft])):\n",
    "                # isso aqui eu pego o valor do elemento que a feture ft pode ter\n",
    "                elemento = classes_unique[i][ft][col]\n",
    "                # Pego o tamanho de linhas do dataset retornado por essa consulta em que o valor da linha para o atributo = elemento\n",
    "                classes_feature_value[i][ft][col] = len(df[df[features[ft]] == elemento])\n",
    "                probs[i][ft][col] = len(df[df[features[ft]] == elemento])\n",
    "\n",
    "    # Geração dos valores de probabilidades de cada valor de cala feature\n",
    "    for i in range(0, len(classes)):  \n",
    "        df = classes[i][0]\n",
    "        for ft in range(0, len(features)):\n",
    "            probs[i][ft] = probs[i][ft].astype(float)\n",
    "            for col in range(0, len(classes_unique[i][ft])):\n",
    "                # isso aqui eu pego o valor do elemento que a feture ft pode ter\n",
    "                # Pego o tamanho de linhas do dataset retornado por essa consulta em que o valor da linha para o atributo = elemento\n",
    "                probs[i][ft][col] = probs[i][ft][col].astype(float)/sum(classes_feature_value[i][ft])\n",
    "\n",
    "    probabilidade_classes = [len(classe[0])/len(dataset) for classe in classes]\n",
    "    \n",
    "    return probs, probabilidade_classes\n",
    "##################################################### \n",
    "def predict(X, features, probs, probabilidade_classes, classes_unique):\n",
    "    results = []\n",
    "    # Ajeitar essa última parte que tá dando erro, mas a lógica tá correta\n",
    "    # Documentar todo esse código\n",
    "    for classe in range(0, len(probs)):\n",
    "        produtorio = 1\n",
    "        for feature in range(0, len(features)):\n",
    "            posix = 0\n",
    "            boolean = False\n",
    "            for i in range(0, len(classes_unique[classe][feature])):\n",
    "                if(X[feature] == classes_unique[classe][feature][i]):\n",
    "                    posix = i\n",
    "                    boolean = True\n",
    "                    break\n",
    "            if(boolean):\n",
    "                produtorio *= probs[classe][feature][posix]\n",
    "        results.append(produtorio)\n",
    "\n",
    "    for i in range(0, len(results)):\n",
    "        results[i] = results[i] * probabilidade_classes[i]\n",
    "    \n",
    "    classes_real_oficial = 0\n",
    "    for i in range(0, len(results)):\n",
    "        if results[i] == max(results):\n",
    "            classes_real_oficial = i\n",
    "    return classes_real_oficial\n",
    "\n",
    "def get_predict(dados, features, probs, probabilidade_classes, classes_unique):\n",
    "    predicts = []\n",
    "    for i in range(0, len(dados)):\n",
    "        data = np.array(dados.loc[dados.index[[i]]])[0]\n",
    "        predicts.append(predict(data, features, probs, probabilidade_classes, classes_unique))\n",
    "    return predicts\n",
    "\n",
    "def accuracy(predicts, teste_y):\n",
    "    cont = 0\n",
    "    for i in range(0, len(predicts)):\n",
    "        teste = np.array(teste_y.loc[teste_y.index[[i]]])[0]\n",
    "        if(predicts[i] == teste):\n",
    "            cont += 1\n",
    "    return cont/len(predicts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06551059730250482\n"
     ]
    }
   ],
   "source": [
    "columns = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "features = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]\n",
    "map_class = {0:'acc', 1:'good', 2:'unacc', 3:'vgood'}\n",
    "\n",
    "dataset = pd.read_csv(\"carData.csv\", names=[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"])\n",
    "dataset = categorize_data(dataset, columns)\n",
    "\n",
    "treino, teste = train_test_split(dataset,test_size=0.3)\n",
    "treino_x = treino[features]\n",
    "treino_y = treino['class']\n",
    "teste_x = teste[features]\n",
    "teste_y = teste['class']\n",
    "\n",
    "classes = summarize_by_class(treino)\n",
    "tabela_probabilidades, probabilidades_classes = calculate_probabilities(treino, features, classes)\n",
    "predicts = get_predict(teste_x, features, tabela_probabilidades, probabilidade_classes, classes_unique)\n",
    "print(accuracy(predicts, teste_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6040462427745664, 0.6069364161849711, 0.6011560693641619, 0.630057803468208, 0.6069364161849711]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.54      0.15        13\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.80      0.81      0.81       236\n",
      "           3       1.00      0.12      0.22        97\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       346\n",
      "   macro avg       0.47      0.37      0.29       346\n",
      "weighted avg       0.83      0.61      0.62       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edson\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for feature in [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]:\n",
    "    dataset[feature] = dataset[feature].astype('category')\n",
    "    dataset[feature] = dataset[feature].cat.codes\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "accuracy = [];\n",
    "\n",
    "for _ in range(0,5):\n",
    "    result = next(kf.split(df), None)\n",
    "    train = dataset.iloc[result[0]]\n",
    "    test =  dataset.iloc[result[1]]\n",
    "    \n",
    "    target_train = train['class']\n",
    "    target_test = test['class']\n",
    "    \n",
    "    train = train[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]]\n",
    "    test = test[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]]\n",
    "    \n",
    "    naive_bayes = GaussianNB()\n",
    "    naive_bayes.fit(train, target_train)\n",
    "    target_pred = naive_bayes.predict(test)\n",
    "    \n",
    "    accuracy.append(accuracy_score(target_test, target_pred))\n",
    "\n",
    "print(accuracy)\n",
    "# Fazer média da acuracia\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(target_pred, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
