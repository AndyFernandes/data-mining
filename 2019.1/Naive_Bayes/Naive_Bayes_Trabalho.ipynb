{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Trabalho\n",
    "\n",
    "## Questão 1\n",
    "\n",
    "Implemente um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizaremos um conjunto de dados referente a qualidade de carros, disponível no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). Este dataset de carros possui as seguintes features e classe:\n",
    "\n",
    "** Attributos **\n",
    "1. buying: vhigh, high, med, low\n",
    "2. maint: vhigh, high, med, low\n",
    "3. doors: 2, 3, 4, 5, more\n",
    "4. persons: 2, 4, more\n",
    "5. lug_boot: small, med, big\n",
    "6. safety: low, med, high\n",
    "\n",
    "** Classes **\n",
    "1. unacc, acc, good, vgood\n",
    "\n",
    "## Questão 2\n",
    "Crie uma versão de sua implementação usando as funções disponíveis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) \n",
    "\n",
    "## Questão 3\n",
    "\n",
    "Analise a acurácia dos dois algoritmos e discuta a sua solução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Resolução\n",
    "\n",
    "## Questão 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [0.5, 0.6, 0.7, 1, 2, 3] => predizer a classe\n",
    "# \n",
    "# p(c|x) = P(X|C)*P(C) / P(X) => P(X|C)*P(C)\n",
    "# MAIOR P(C|X) ai a gente retorna que é a c\n",
    "\n",
    "# probabilidade da classe = p(c) => len(classe)/numero de linhas do dataset\n",
    "# probabilidade do elemento x dado a classe = p(x|c) = p(x[0]|c)*p(x[1]|c)*p(x[2]|c)*...*p(x[5]|c)  \n",
    "# X = [0.5, 0.6, 0.7, 1, 2, 3]\n",
    "# probabilidade do elemento x = p(x)\n",
    "\n",
    "# probabilidade de cada elemento para cada feature para cada classe => elemento/len(classe)\n",
    "# os valores da classe estão ordenados de 0 a 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from statistics import mean\n",
    "    \n",
    "def categorize_data(dataset, columns):\n",
    "    # Categorizando os dados\n",
    "    for feature in columns:\n",
    "        dataset[feature] = dataset[feature].astype('category')\n",
    "        dataset[feature] = dataset[feature].cat.codes\n",
    "    return dataset\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "    classes = [[], [], [], []]\n",
    "    # separando por classe\n",
    "    for row in dataset['class'].unique():\n",
    "        classes[row].append(dataset[dataset['class'] == row])\n",
    "    return classes\n",
    "\n",
    "def calculate_probabilities(dataset, features, classes): \n",
    "    #separando cada valor de cada feature pra cada classe\n",
    "    classes_unique = [[], [], [], []]\n",
    "    classes_feature_value = [[], [], [], []]\n",
    "    probs = [[], [], [], []]\n",
    "    for i in range(0, len(classes)):  \n",
    "        df = classes[i][0]\n",
    "        for ft in features:   \n",
    "            # Classes_unique vai ser usado para mapear os valores direito, já que não estão ordenados\n",
    "            classes_unique[i].append(df[ft].unique())\n",
    "            classes_feature_value[i].append(df[ft].unique())\n",
    "            probs[i].append(df[ft].unique())\n",
    "\n",
    "    # Gerando a contagem de cada elemento de cada feature para cada classe \n",
    "    # Percorre as classes\n",
    "    for i in range(0, len(classes)):  \n",
    "        df = classes[i][0]\n",
    "        # Percorre as features dentro da classe\n",
    "        for ft in range(0, len(features)):\n",
    "            # Percorrer os valores de dentro das features\n",
    "            for col in range(0, len(classes_unique[i][ft])):\n",
    "                # isso aqui eu pego o valor do elemento que a feture ft pode ter\n",
    "                elemento = classes_unique[i][ft][col]\n",
    "                # Pego o tamanho de linhas do dataset retornado por essa consulta em que o valor da linha para o atributo = elemento\n",
    "                classes_feature_value[i][ft][col] = len(df[df[features[ft]] == elemento])\n",
    "                probs[i][ft][col] = len(df[df[features[ft]] == elemento])\n",
    "\n",
    "    # Geração dos valores de probabilidades de cada valor de cala feature\n",
    "    for i in range(0, len(classes)):  \n",
    "        df = classes[i][0]\n",
    "        for ft in range(0, len(features)):\n",
    "            probs[i][ft] = probs[i][ft].astype(float)\n",
    "            for col in range(0, len(classes_unique[i][ft])):\n",
    "                # isso aqui eu pego o valor do elemento que a feture ft pode ter\n",
    "                # Pego o tamanho de linhas do dataset retornado por essa consulta em que o valor da linha para o atributo = elemento\n",
    "                probs[i][ft][col] = probs[i][ft][col].astype(float)/sum(classes_feature_value[i][ft])\n",
    "\n",
    "    probabilidade_classes = [len(classe[0])/len(dataset) for classe in classes]\n",
    "    \n",
    "    return probs, probabilidade_classes\n",
    "##################################################### \n",
    "def predict(X, features, probs, probabilidade_classes, classes_unique):\n",
    "    results = []\n",
    "    # Ajeitar essa última parte que tá dando erro, mas a lógica tá correta\n",
    "    # Documentar todo esse código\n",
    "    for classe in range(0, len(probs)):\n",
    "        produtorio = 1\n",
    "        for feature in range(0, len(features)):\n",
    "            posix = 0\n",
    "            boolean = False\n",
    "            print(feature)\n",
    "            print(classes_unique[classe])\n",
    "            break\n",
    "#             for i in range(0, len(classes_unique[classe][feature])):\n",
    "#                 if(X[feature] == classes_unique[classe][feature][i]):\n",
    "#                     posix = i\n",
    "#                     boolean = True\n",
    "#                     break\n",
    "            if(boolean):\n",
    "                produtorio *= probs[classe][feature][posix]\n",
    "        results.append(produtorio)\n",
    "\n",
    "    for i in range(0, len(results)):\n",
    "        results[i] = results[i] * probabilidade_classes[i]\n",
    "    \n",
    "    classes_real_oficial = 0\n",
    "    for i in range(0, len(results)):\n",
    "        if results[i] == max(results):\n",
    "            classes_real_oficial = i\n",
    "    return classes_real_oficial\n",
    "\n",
    "def get_predict(dados, features, probs, probabilidade_classes, classes_unique):\n",
    "    predicts = []\n",
    "    for i in range(0, len(dados)):\n",
    "        data = np.array(dados.loc[dados.index[[i]]])[0]\n",
    "        predicts.append(predict(data, features, probs, probabilidade_classes, classes_unique))\n",
    "    return predicts\n",
    "\n",
    "def accuracy(predicts, teste_y):\n",
    "    cont = 0\n",
    "    for i in range(0, len(predicts)):\n",
    "        teste = np.array(teste_y.loc[teste_y.index[[i]]])[0]\n",
    "        if(predicts[i] == teste):\n",
    "            cont += 1\n",
    "    return 100*(cont/len(predicts))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "features = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]\n",
    "map_class = {0:'acc', 1:'good', 2:'unacc', 3:'vgood'}\n",
    "\n",
    "dataset = pd.read_csv(\"carData.csv\", names=[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"])\n",
    "dataset = categorize_data(dataset, columns)\n",
    "\n",
    "treino, teste = train_test_split(dataset,test_size=0.3)\n",
    "treino_x = treino[features]\n",
    "treino_y = treino['class']\n",
    "teste_x = teste[features]\n",
    "teste_y = teste['class']\n",
    "\n",
    "classes = summarize_by_class(treino)\n",
    "tabela_probabilidades, probabilidade_classes = calculate_probabilities(treino, features, classes)\n",
    "# predicts = get_predict(teste_x, features, tabela_probabilidades, probabilidade_classes, treino_y.unique())\n",
    "# print(accuracy(predicts, teste_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNB(x, y):\n",
    "    classes = np.unique(y)\n",
    "    K = classes.shape[0]\n",
    "    D = x.shape[1]\n",
    "    \n",
    "    prioridadeClasses = np.array([np.sum(y == k) for k in classes])/y.shape[0]\n",
    "    \n",
    "    mean = np.zeros((D, K))\n",
    "    var = np.zeros((D, K))\n",
    "    for k in classes:\n",
    "        xk = x[y == k]\n",
    "        mean[:,k] = np.mean(xk, axis = 0)\n",
    "        var[:, k] = np.sum((xk - mean[:, k])**2, axis = 0) / xk.shape[0]\n",
    "    \n",
    "    return {'classes': classes, 'prioridade': prioridadeClasses, 'K': K, 'D': D, 'mean': mean, 'var':var}\n",
    "\n",
    "def predic(model, x):\n",
    "    pred = np.zeros((x.shape[0], model['K']))\n",
    "    \n",
    "    for k in range(model['K']):\n",
    "        pred[:,k] = - 0.5 * np.sum(np.log(2*np.pi*model['var'][:,k])) \\\n",
    "                    - 0.5 * np.sum((x - model['mean'][:,k])**2 / model['var'][:,k], axis=1) \\\n",
    "                    + model['prioridade'][k]\n",
    "    return model['classes'][np.argmax(pred, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03468208092485549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = createNB(np.array(treino_x), np.array(treino_y))\n",
    "model\n",
    "predict = predic(model, teste_x)\n",
    "# classe\n",
    "accuracy_score(teste_y, predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\andre\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\andre\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\andre\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6358381502890174, 0.6040462427745664, 0.6358381502890174, 0.6040462427745664, 0.661849710982659]\n",
      "[0.02601156069364162, 0.04046242774566474, 0.04335260115606936, 0.046242774566473986, 0.028901734104046242]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.38      0.14        16\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.85      0.86      0.85       248\n",
      "           3       1.00      0.12      0.22        82\n",
      "\n",
      "    accuracy                           0.66       346\n",
      "   macro avg       0.48      0.34      0.30       346\n",
      "weighted avg       0.85      0.66      0.67       346\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      0.03      0.06       346\n",
      "\n",
      "    accuracy                           0.03       346\n",
      "   macro avg       0.25      0.01      0.01       346\n",
      "weighted avg       1.00      0.03      0.06       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\andre\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for feature in [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]:\n",
    "    dataset[feature] = dataset[feature].astype('category')\n",
    "    dataset[feature] = dataset[feature].cat.codes\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "accuracy1 = [];\n",
    "accuracy2 = [];\n",
    "\n",
    "for _ in range(0,5):\n",
    "    result = next(kf.split(dataset), None)\n",
    "    train = dataset.iloc[result[0]]\n",
    "    test =  dataset.iloc[result[1]]\n",
    "    \n",
    "    target_train = train['class']\n",
    "    target_test = test['class']\n",
    "    \n",
    "    train = train[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]]\n",
    "    test = test[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]]\n",
    "    \n",
    "    naive_bayes = GaussianNB()\n",
    "    naive_bayes.fit(train, target_train)\n",
    "    target_pred = naive_bayes.predict(test)\n",
    "    \n",
    "    model = createNB(np.array(train), np.array(target_train))\n",
    "    predict = predic(model, test)\n",
    "    \n",
    "    accuracy1.append(accuracy_score(target_test, target_pred))\n",
    "    accuracy2.append(accuracy_score(target_test, predict))\n",
    "\n",
    "print(accuracy1)\n",
    "print(accuracy2)\n",
    "# Fazer média da acuracia\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(target_pred, target_test))\n",
    "print(\"--------------------------------------------------\")\n",
    "print(classification_report(predict, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
